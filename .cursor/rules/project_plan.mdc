# Project Plan: Employee Attrition Prediction

This plan outlines the steps to build, evaluate, and improve a model for predicting employee attrition.

### Phase 1: Project Setup & Data Loading
1.  **[COMPLETED]** Set up `.cursorrules`.
2.  **[PENDING]** Create the `build.sbt` file with Spark dependencies.
3.  **[PENDING]** Create the main application object.
4.  **[PENDING]** Find and download the "HR Analytics" dataset.
5.  **[PENDING]** Load the dataset into a Spark DataFrame with a defined schema.

### Phase 2: Preprocessing & Feature Engineering
1.  **[PENDING]** Handle missing values.
2.  **[PENDING]** Encode categorical columns (e.g., `JobRole`, `OverTime`) into numerical representations using `StringIndexer` and `OneHotEncoder`.
3.  **[PENDING]** Encode the target variable `Attrition` using `StringIndexer`.
4.  **[PENDING]** Assemble all feature columns into a single `features` vector using `VectorAssembler`.

### Phase 3: Model Training & Evaluation
1.  **[PENDING]** Split the data into training and testing sets.
2.  **[PENDING]** Define an initial classification model (e.g., `LogisticRegression`).
3.  **[PENDING]** Create and fit the full `Pipeline` on the training data.
4.  **[PENDING]** Make predictions on the test data.
5.  **[PENDING]** Evaluate the model using `BinaryClassificationEvaluator` (e.g., checking the Area Under ROC).

### Phase 4: Model Improvement
1.  **[PENDING]** Implement `CrossValidator` and `ParamGridBuilder` to find optimal hyperparameters.
2.  **[PENDING]** Experiment with other algorithms like `RandomForestClassifier` or `GBTClassifier`.
description:
globs:
alwaysApply: false
---
